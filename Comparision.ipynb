{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ada10a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification,AutoModelForSequenceClassification,AutoConfig\n",
    "import torch\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38030c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions( sentence, tokenizer, model ):\n",
    "  # Let us first tokenize the sentence - split words into subwords\n",
    "  tok_sentence = tokenizer(sentence, return_tensors='pt')\n",
    "\n",
    "  with torch.no_grad():\n",
    "    # we will send the tokenized sentence to the model to get predictions\n",
    "    logits = model(**tok_sentence).logits.argmax(-1)\n",
    "    \n",
    "    # We will map the maximum predicted class id with the class label\n",
    "    predicted_tokens_classes = [model.config.id2label[t.item()] for t in logits[0]]\n",
    "    \n",
    "    predicted_labels = []\n",
    "    \n",
    "    previous_token_id = 0\n",
    "    # we need to assign the named entity label to the head word and not the following sub-words\n",
    "    word_ids = tok_sentence.word_ids()\n",
    "    for word_index in range(len(word_ids)):\n",
    "        if word_ids[word_index] == None:\n",
    "            previous_token_id = word_ids[word_index]\n",
    "        elif word_ids[word_index] == previous_token_id:\n",
    "            previous_token_id = word_ids[word_index]\n",
    "        else:\n",
    "            predicted_labels.append( predicted_tokens_classes[ word_index ] )\n",
    "            previous_token_id = word_ids[word_index]\n",
    "    \n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28f7bdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_metrics(true_labels, predicted_labels):\n",
    "    \n",
    "    true_labels_flat = [label for sublist in true_labels for label in sublist]\n",
    "    predicted_labels_flat = [label for sublist in predicted_labels for label in sublist]\n",
    "    \n",
    "    #because manual labelling and different tokenizer can can generate different length token lists \n",
    "    minlen = min(len(true_labels_flat),len(predicted_labels_flat))\n",
    "    true_labels_flat = true_labels_flat[:minlen]\n",
    "    predicted_labels_flat = predicted_labels_flat[:minlen]\n",
    "    \n",
    "    precision = precision_score(true_labels_flat, predicted_labels_flat, average='weighted',zero_division=1)\n",
    "    recall = recall_score(true_labels_flat, predicted_labels_flat, average='weighted',zero_division=1)\n",
    "\n",
    "    f1 = f1_score(true_labels_flat, predicted_labels_flat, average='weighted',zero_division=1)\n",
    "    macro_f1 = f1_score(true_labels_flat, predicted_labels_flat, average='macro',zero_division=1)\n",
    "\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"F1: \", f1)\n",
    "    print(\"Macro F1: \", macro_f1)\n",
    "\n",
    "    return precision, recall, f1, macro_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed9a1e4",
   "metadata": {},
   "source": [
    "# Loading the saved IndicNER model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bef650eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# config = AutoConfig.from_pretrained('/Users/abinash/Desktop/ComputationalLinguistics/Assignment2/IndicNER/')\n",
    "model_ner = AutoModelForTokenClassification.from_pretrained('./IndicNER/')\n",
    "tokenizer_ner = AutoTokenizer.from_pretrained(\"ai4bharat/IndicNER\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2daec054",
   "metadata": {},
   "source": [
    "# Loading the IndicBERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c6051c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_bert = AutoConfig.from_pretrained('./IndicBERT/')\n",
    "tokenizer_bert = AutoTokenizer.from_pretrained(\"ai4bharat/indic-bert\")\n",
    "model_bert = AutoModelForTokenClassification.from_pretrained('./IndicBERT/', num_labels=7 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f226047",
   "metadata": {},
   "source": [
    "# Loading the sentenses from Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "346f99b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['उन्होंने आज ट्वीट किया, ‘क्या किसी किसी पीटी ने प्रस्तावित जीएसटी संविधान संशोधन में जीएसटीएन संभावनाओं और भूमिका का अध्ययन किया है।\\n', 'कुमुद महाजन का कहना है कि वर्तमान समय की भागदौड़ वाली जीवनशैली के कारण लोगों में सिरदर्द\\xa0\\n', 'मोदी सरकार ने गाय के लिए भी बजट में विशेष तवज्जो दी है.\\n', \"शायद हमें कभी ना पता चले लेकिन यह बहुत दुखद घटना है।' खबर में बताया गया है कि दोनों 2014 से शादीशुदा थे और दोनों सॉफ्टवेयर इंजीनियर थे। \\n\", 'फरवरी में पुलवामा आतंकवादी हमले के बाद भारत और पाकिस्तान के संबंधों में कटुता आने के कारण पाकिस्तानी नौसेना ने अपने मित्र देश की नौसेना के महत्वपूर्ण आयोजन में भाग नहीं लिया.\\n', 'इस बात की जानकारी फ्लॉरेडा के शेरिफ ऑफिस ने बताई.\\n', 'मुख्यमंत्री ने कहा कि सभी गांवों को सड़कों से जोड़ना है।\\n', '2-3 किलोमीटर की परिधि में फैले इस छोटे से इलाके ने मलक्का के 600 सालों के इतिहास को समेट रखा है.\\n', 'इसलिए मैंने शुरू में कहा था इंदिरा इज इंडिया, जो नारा उस समय कांग्रेस ने लगाया था, कांग्रेस अध्यक्ष ने लगाया था और जिसका परिणाम 1977 में देखने को मिला.\\n', 'इस दौरान वह आज़ादी के नारे भी लगा रही हैं।\\n', 'सुंदर फूलों के संचार की भाषा अद्भुत खुशबू आ रही हैं. छवि में कुछ भी नहीं है हमें सच में अद्भुत रंग के रूप में के रूप में ज्यादा आकर्षित नहीं करता. \\n', 'बता दें, कंप्यूटर आधारित परीक्षा 14 अक्टूबर, 2019 से 16 अक्टूबर, 2019 को आयोजित की गई थी.\\n', 'औली में 25 दिसम्बर को बर्फ देखने के लिये काफी लोग आते हैं और काफी लोग यहां पर स्कीइंग के लिये आते हैं । \\n', 'मैंने कभी भी तुम्हारा मित्र के अलावा किसी और तरीके से स्पर्श किया है?\\n', 'पुष्\\u200dकर पुष्\\u200dप और मुकेश चौरसिया ने सभी परिचित न्यूज पोर्टल संचालकों को इस फुटेज का लिंक तथा फुटेज की ट्रांसस्क्रिप्\\u200dट तैयार कर भेज दिया ताकि उसके आधार पर यशवंत के खिलाफ माहौल बताया जा सके। \\n', 'किसान सम्मान निधि योजना का तीसरा किस्त जल्द किसानों को मिलेगा।\\n', 'वहीं तहरीर के आधार पर पुलिस संदिग्धों से पूछताछ कर रही है.\\n', 'इस चैनल के दिल्ली ब्यूरो प्रमुख मुकेश चौरसिया ने कापड़ी के साथ हुई अपनी इस बातचीत के फुटेज को यू-ट्यूब पर अपलोड कर दिया। \\n', 'नीतू बाला ने बताया कि वह मोहाली में एक प्राइवेट कंपनी में काम करती है और शाही माजरा में किराये पर रहती है।\\n', 'गौरतलब है कि प्रदेश में एक माह के दौरान अब तक चार किसान आत्महत्या कर चुके हैं।\\n', 'जिससे उनकी गाड़ी दूर तक पलटती हुई चली गई और स्कार्पियो चालक गाड़ी को घटनास्थल से लेकर फरार हो गया।\\n', 'ऑस्ट्रेलियाई दर्शक अपनी टीम की क्रिकेट को बहुत ही ज्यादा प्यार करते हैं, लेकिन. . Updated: 27 नवम्बर, 2018 12:06 AM\\n', 'यूके और चीन के बीच मालगाड़ी सेवा के तहत पहली ट्रेन आज इंगलैंड के शहर एसेक्स से चली।\\n', 'विचारों से मां भारती की तस्वीर बदलने का काम भाजपा कर रही है।\\n', 'परिवार, बालक के विकास की प्रथम पाठशाला है. यह बालक में निहित योग्यताओं एवं क्षमताओं का विकास करता है. परिवार का प्रत्येक सदस्य, बालक के विकास में योगदान देता है.']\n",
      "['उन्होंने आज ट्वीट किया, ‘क्या किसी किसी पीटी ने प्रस्तावित जीएसटी संविधान संशोधन में जीएसटीएन संभावनाओं और भूमिका का अध्ययन किया है।', 'कुमुद महाजन का कहना है कि वर्तमान समय की भागदौड़ वाली जीवनशैली के कारण लोगों में सिरदर्द', 'मोदी सरकार ने गाय के लिए भी बजट में विशेष तवज्जो दी है.', \"शायद हमें कभी ना पता चले लेकिन यह बहुत दुखद घटना है।' खबर में बताया गया है कि दोनों 2014 से शादीशुदा थे और दोनों सॉफ्टवेयर इंजीनियर थे।\", 'फरवरी में पुलवामा आतंकवादी हमले के बाद भारत और पाकिस्तान के संबंधों में कटुता आने के कारण पाकिस्तानी नौसेना ने अपने मित्र देश की नौसेना के महत्वपूर्ण आयोजन में भाग नहीं लिया.', 'इस बात की जानकारी फ्लॉरेडा के शेरिफ ऑफिस ने बताई.', 'मुख्यमंत्री ने कहा कि सभी गांवों को सड़कों से जोड़ना है।', '2-3 किलोमीटर की परिधि में फैले इस छोटे से इलाके ने मलक्का के 600 सालों के इतिहास को समेट रखा है.', 'इसलिए मैंने शुरू में कहा था इंदिरा इज इंडिया, जो नारा उस समय कांग्रेस ने लगाया था, कांग्रेस अध्यक्ष ने लगाया था और जिसका परिणाम 1977 में देखने को मिला.', 'इस दौरान वह आज़ादी के नारे भी लगा रही हैं।', 'सुंदर फूलों के संचार की भाषा अद्भुत खुशबू आ रही हैं. छवि में कुछ भी नहीं है हमें सच में अद्भुत रंग के रूप में के रूप में ज्यादा आकर्षित नहीं करता.', 'बता दें, कंप्यूटर आधारित परीक्षा 14 अक्टूबर, 2019 से 16 अक्टूबर, 2019 को आयोजित की गई थी.', 'औली में 25 दिसम्बर को बर्फ देखने के लिये काफी लोग आते हैं और काफी लोग यहां पर स्कीइंग के लिये आते हैं ।', 'मैंने कभी भी तुम्हारा मित्र के अलावा किसी और तरीके से स्पर्श किया है?', 'पुष्\\u200dकर पुष्\\u200dप और मुकेश चौरसिया ने सभी परिचित न्यूज पोर्टल संचालकों को इस फुटेज का लिंक तथा फुटेज की ट्रांसस्क्रिप्\\u200dट तैयार कर भेज दिया ताकि उसके आधार पर यशवंत के खिलाफ माहौल बताया जा सके।', 'किसान सम्मान निधि योजना का तीसरा किस्त जल्द किसानों को मिलेगा।', 'वहीं तहरीर के आधार पर पुलिस संदिग्धों से पूछताछ कर रही है.', 'इस चैनल के दिल्ली ब्यूरो प्रमुख मुकेश चौरसिया ने कापड़ी के साथ हुई अपनी इस बातचीत के फुटेज को यू-ट्यूब पर अपलोड कर दिया।', 'नीतू बाला ने बताया कि वह मोहाली में एक प्राइवेट कंपनी में काम करती है और शाही माजरा में किराये पर रहती है।', 'गौरतलब है कि प्रदेश में एक माह के दौरान अब तक चार किसान आत्महत्या कर चुके हैं।', 'जिससे उनकी गाड़ी दूर तक पलटती हुई चली गई और स्कार्पियो चालक गाड़ी को घटनास्थल से लेकर फरार हो गया।', 'ऑस्ट्रेलियाई दर्शक अपनी टीम की क्रिकेट को बहुत ही ज्यादा प्यार करते हैं, लेकिन. . Updated: 27 नवम्बर, 2018 12:06 AM', 'यूके और चीन के बीच मालगाड़ी सेवा के तहत पहली ट्रेन आज इंगलैंड के शहर एसेक्स से चली।', 'विचारों से मां भारती की तस्वीर बदलने का काम भाजपा कर रही है।', 'परिवार, बालक के विकास की प्रथम पाठशाला है. यह बालक में निहित योग्यताओं एवं क्षमताओं का विकास करता है. परिवार का प्रत्येक सदस्य, बालक के विकास में योगदान देता है.']\n"
     ]
    }
   ],
   "source": [
    "with open('sentences.txt', 'r') as file:\n",
    "    sentences = file.readlines()\n",
    "\n",
    "print(sentences)\n",
    "#remove the newline character from the sentences\n",
    "sentences = [sentence.strip() for sentence in sentences]\n",
    "\n",
    "print(sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274a8aca",
   "metadata": {},
   "source": [
    "Manually written NER Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5c0bf1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O O O O O O O O O O O O O O O O O O O O O O O O O\\n', 'B-PER I-PER O O O O O O O O O O O O O O O\\n', 'B-ORG I-ORG O B-MISC O O O O O O O O O O\\n', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\\n', 'O O B-LOC O O O O B-LOC O B-LOC O O O O O O O B-ORG I-ORG O O O O O B-ORG O O O O O O O\\n', 'O O O O B-LOC O B-ORG B-ORG O O O\\n', 'B-PER O O O O O O O O O O O\\n', 'O O O O O O O O O O O O O B-LOC O O O O O O O O O O\\n', 'O O O O O O B-PER O O O O O O O B-ORG O O O O B-ORG O O O O O O O O O O O O O O\\n', 'O O O O O O O O O O O\\n', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\\n', 'O O O O O O O O O O O O O O O O O O O O O\\n', 'B-LOC O O O O O O O O O O O O O O O O O O O O O O O\\n', 'O O O O O O O O O O O O O O O\\n', 'B-PER I-PER O B-PER I-PER O O O O O O O O O O O O O O O O O O O O O O O B-PER O O O O O O O\\n', 'B-MISC I-MISC I-MISC I-MISC O O O O O O O O\\n', 'O O O O O O O O O O O O O \\n', 'O O O B-ORG I-ORG O B-PER I-PER O B-PER O O O O O O O O O O O O O O O O O\\n', 'B-PER I-PER O O O O B-LOC O O O O O O O O O B-PER I-PER O O O O O O\\n', 'O O O O O O O O O O O O O O O O O O\\n', 'O O O O O O O O O O O O O O O O O O O O O\\n', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O\\n', 'B-LOC O B-LOC O O O O O O O O O B-LOC O O B-LOC O O O\\n', 'O O B-PER I-PER O O O O O B-ORG O O O O\\n', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O']\n",
      "['O O O O O O O O O O O O O O O O O O O O O O O O O', 'B-PER I-PER O O O O O O O O O O O O O O O', 'B-ORG I-ORG O B-MISC O O O O O O O O O O', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O', 'O O B-LOC O O O O B-LOC O B-LOC O O O O O O O B-ORG I-ORG O O O O O B-ORG O O O O O O O', 'O O O O B-LOC O B-ORG B-ORG O O O', 'B-PER O O O O O O O O O O O', 'O O O O O O O O O O O O O B-LOC O O O O O O O O O O', 'O O O O O O B-PER O O O O O O O B-ORG O O O O B-ORG O O O O O O O O O O O O O O', 'O O O O O O O O O O O', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O O O O O O O O', 'B-LOC O O O O O O O O O O O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O O', 'B-PER I-PER O B-PER I-PER O O O O O O O O O O O O O O O O O O O O O O O B-PER O O O O O O O', 'B-MISC I-MISC I-MISC I-MISC O O O O O O O O', 'O O O O O O O O O O O O O', 'O O O B-ORG I-ORG O B-PER I-PER O B-PER O O O O O O O O O O O O O O O O O', 'B-PER I-PER O O O O B-LOC O O O O O O O O O B-PER I-PER O O O O O O', 'O O O O O O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O', 'B-LOC O B-LOC O O O O O O O O O B-LOC O O B-LOC O O O', 'O O B-PER I-PER O O O O O B-ORG O O O O', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O']\n",
      "[['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-ORG', 'I-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-ORG', 'B-ORG', 'O', 'O', 'O'], ['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-PER', 'I-PER', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'B-PER', 'I-PER', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'B-LOC', 'O', 'O', 'O'], ['O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n"
     ]
    }
   ],
   "source": [
    "with open('truth.txt', 'r') as file:\n",
    "    truth = file.readlines()\n",
    "\n",
    "\n",
    "print(truth)\n",
    "#remove the newline character from the truth\n",
    "truth = [sentence.strip() for sentence in truth]\n",
    "print(truth)\n",
    "\n",
    "true_labels = [sentence.split() for sentence in truth]\n",
    "print(true_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea9c9d5",
   "metadata": {},
   "source": [
    "# Comparing IndicNER with manually written NER tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d04cf47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9308647652834692\n",
      "Recall:  0.9274047186932849\n",
      "F1:  0.9580580464240267\n",
      "Macro F1:  0.5160007297938333\n",
      "(0.9308647652834692, 0.9274047186932849, 0.9580580464240267)\n"
     ]
    }
   ],
   "source": [
    "# predicing the named entities using the NER model\n",
    "predicted_labels_ner = []\n",
    "for sentence in sentences:\n",
    "    predicted_labels_ner.append(get_predictions(sentence, tokenizer_ner, model_ner))\n",
    "\n",
    "print(calculate_metrics(true_labels, predicted_labels_ner))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6586b6ce",
   "metadata": {},
   "source": [
    "# Comparing IndicBERT with manually written NER tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4647ea42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.8479116740842176\n",
      "Recall:  0.8681102362204725\n",
      "F1:  0.922591599940071\n",
      "Macro F1:  0.5480385247827109\n",
      "(0.8479116740842176, 0.8681102362204725, 0.922591599940071)\n"
     ]
    }
   ],
   "source": [
    "# predicing the named entities using the BERT model\n",
    "predicted_labels_bert = []\n",
    "for sentence in sentences:\n",
    "    predicted_labels_bert.append(get_predictions(sentence, tokenizer_bert, model_bert))\n",
    "\n",
    "print(calculate_metrics(true_labels, predicted_labels_bert))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db94ed6",
   "metadata": {},
   "source": [
    "# Comparing ChatGPT with manually written NER tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bdfee695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O O O O O B-LOC O O O O O O O O O O O O O O O O O O O O O O O O O\\n', 'B-PER I-PER O O O O O O O O O O O O O O O O\\n', 'B-PER O O O O O O O O O O O O O O\\n', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\\n', 'O O B-LOC O B-LOC O O O O O O O O B-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\\n', 'O O O O B-LOC O B-ORG I-ORG O O\\n', 'B-PER O O O O O O O O O O\\n', 'O O O O O O O O O O O O O O O O B-LOC O O O O O O\\n', 'O O O O B-PER I-PER I-PER O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\\n', 'O O O O O O O O O O O O O O O O O O O O O O O O O\\n', 'O O O O O O O O O O O O O O O O O O O O O O O O\\n', \"'O O O O O O O O O O O O O O O O O O O O O O O O O O O O\\n\", 'B-LOC O O O O O O O O O O O O O O O O O O O O O O O\\n', 'O O O O O O O O O O O O O O O O O O O\\n', 'B-PER I-PER O O O B-PER I-PER O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\\n', 'O O O O O O O O O O O O O O O\\n', 'O O O O O O O O O O O O O O O\\n', 'O O O O O O B-PER I-PER O O O O O O O O O O O O O O O\\n', 'B-PER I-PER O O O O O O O O O O O O O O O O O O O O\\n', 'O O O O O O O O O O O O O O O O O O O O O O O O\\n', 'O O O O O O O O O O O O O O O O O O O O O O O O O O\\n', 'B-MISC O O O O O O O O O O O O O O O O O O O O O O O O O O\\n', 'B-LOC O O B-LOC O O O O O O O O O O O O\\n', 'O O O O O O B-ORG O O O O O O O O\\n', 'O O O O O O O O O O O O O O O O O O O O O O O O']\n",
      "['O O O O O B-LOC O O O O O O O O O O O O O O O O O O O O O O O O O', 'B-PER I-PER O O O O O O O O O O O O O O O O', 'B-PER O O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O', 'O O B-LOC O B-LOC O O O O O O O O B-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O', 'O O O O B-LOC O B-ORG I-ORG O O', 'B-PER O O O O O O O O O O', 'O O O O O O O O O O O O O O O O B-LOC O O O O O O', 'O O O O B-PER I-PER I-PER O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O O O O O O O O O O O', \"'O O O O O O O O O O O O O O O O O O O O O O O O O O O O\", 'B-LOC O O O O O O O O O O O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O O O O O O', 'B-PER I-PER O O O B-PER I-PER O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O O', 'O O O O O O B-PER I-PER O O O O O O O O O O O O O O O', 'B-PER I-PER O O O O O O O O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O O O O O O O O O O O O O', 'B-MISC O O O O O O O O O O O O O O O O O O O O O O O O O O', 'B-LOC O O B-LOC O O O O O O O O O O O O', 'O O O O O O B-ORG O O O O O O O O', 'O O O O O O O O O O O O O O O O O O O O O O O O']\n",
      "[['O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-ORG', 'I-ORG', 'O', 'O'], ['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], [\"'O\", 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-PER', 'I-PER', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-LOC', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n"
     ]
    }
   ],
   "source": [
    "with open('chatgpt.txt', 'r') as file:\n",
    "    chatgpt_sentences = file.readlines()\n",
    "\n",
    "print(chatgpt_sentences)\n",
    "\n",
    "#remove the newline character from the sentences\n",
    "chatgpt_sentences = [sentence.strip() for sentence in chatgpt_sentences]\n",
    "\n",
    "print(chatgpt_sentences)\n",
    "\n",
    "chatgpt_lebel = [sentence.split() for sentence in chatgpt_sentences]\n",
    "print(chatgpt_lebel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97a57ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.8434016074669433\n",
      "Recall:  0.8711433756805808\n",
      "F1:  0.9322678977322785\n",
      "Macro F1:  0.7702265372168284\n",
      "(0.8434016074669433, 0.8711433756805808, 0.9322678977322785)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(calculate_metrics(true_labels, chatgpt_lebel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02124ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(sentences)):\n",
    "#     print(sentences[i], len(sentences[i]))\n",
    "#     print(true_labels[i], len(true_labels[i]))\n",
    "#     print(predicted_labels_ner[i], len(predicted_labels_ner[i]))\n",
    "#     print(predicted_labels_bert[i], len(predicted_labels_bert[i]))\n",
    "#     print(chatgpt_lebel[i], len(chatgpt_lebel[i]))\n",
    "#     print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef025f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove \",\" \"[\" \"]\" from chatgpt_truth usinf regex\n",
    "# import re\n",
    "# text = \"\"\"['O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
    "# ['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
    "# ['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
    "# ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
    "# ['O', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
    "# ['O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-ORG', 'I-ORG', 'O', 'O']\n",
    "# ['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
    "# ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O']\n",
    "# ['O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
    "# ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
    "# ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
    "# ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
    "# ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
    "# ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
    "# ['B-PER', 'I-PER', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
    "# ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
    "# ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
    "# ['O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
    "# ['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
    "# ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
    "# ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
    "# ['B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
    "# ['B-LOC', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
    "# ['O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
    "# ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\"\"\"\n",
    "# text = [re.sub(r'[\\[\\],]', '', sentence) for sentence in text.split('\\n')]\n",
    "# print(text)\n",
    "\n",
    "# # remove ' form the text\n",
    "# text = [sentence.replace(\"'\", \"\") for sentence in text]\n",
    "# print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7a4777",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
